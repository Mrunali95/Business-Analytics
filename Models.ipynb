{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Models.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP+eZw47rpuPqeoR1J4mvHd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"g6M9AfcbD53c","colab_type":"code","colab":{}},"source":["## Cleaning of comments\n","\n","import re\n","def clean_comments(text): \n","        ''' \n","        Utility function to clean tweet text by removing links, special characters \n","        using simple regex statements. \n","        '''\n","        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", text).split())\n","ct = []\n","for t in range(len(reviews)):\n","    ct.append(clean_comments(reviews[t]))\n","    \n","data1['Clear_Comments']=ct\n","\n","\n","## converting text into vectors \n","\n","import nltk\n","nltk.download('stopwords')\n","\n","comments = []\n","for a in range(len(data1['Clear_Comments'])):\n","    comments.append(data1['Clear_Comments'][a].lower())\n","\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","vectorizer = TfidfVectorizer (max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words('english'))\n","processed_features = vectorizer.fit_transform(comments).toarray()\n","\n","\n","##Data splitting into training and testing\n","\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(processed_features, data1['sentiment'], test_size = 0.20)\n","\n","\n","## Apply SVM\n","from sklearn.svm import SVC\n","svclassifier = SVC(kernel='linear')\n","model = svclassifier.fit(X_train, y_train)\n","y_pred = svclassifier.predict(X_test)\n","\n","## Evaluation of SVM results\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, mean_absolute_error\n","from math import sqrt\n","\n","print(confusion_matrix(y_test,y_pred))\n","print(classification_report(y_test,y_pred))\n","print(accuracy_score(y_test, y_pred))\n","print(model.score(X_train, y_train))\n","print(\"RMSE\", sqrt(mean_squared_error(y_test,y_pred)))\n","print(\"MAE\", mean_absolute_error(y_test, y_pred))\n","\n","\n","\n","### Gaussian Naive Bayes \n","\n","from sklearn.naive_bayes import GaussianNB\n","gnb = GaussianNB()\n","gnb.fit(X_train, y_train)\n","y_pred = gnb.predict(X_test)\n","\n","\n","### evaluation of naive bayes\n","\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, mean_absolute_error\n","from math import sqrt\n","\n","print(confusion_matrix(y_test,y_pred))\n","print(classification_report(y_test,y_pred))\n","print(accuracy_score(y_test, y_pred))\n","print(gnb.score(X_train, y_train))\n","print(\"RMSE\", sqrt(mean_squared_error(y_test,p)))\n","print(\"MAE\", mean_absolute_error(y_test, p))\n","\n","\n","## Convolutional Neural network\n","### do not perform vectorization for CNN\n","\n","import pandas as pd\n","import numpy as np\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","\n","from numpy import array\n","from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers.core import Activation, Dropout, Dense\n","from keras.layers import Flatten\n","from keras.layers import GlobalMaxPooling1D\n","from keras.layers.embeddings import Embedding\n","from keras.preprocessing.text import Tokenizer\n","\n","### tokenize\n","\n","tokenizer = Tokenizer(num_words=5000)\n","tokenizer.fit_on_texts(X_train)\n","\n","X_train = tokenizer.texts_to_sequences(X_train)\n","X_test = tokenizer.texts_to_sequences(X_test)\n","\n","## finds the vocabulary size and then perform padding on both train and test set\n","\n","# Adding 1 because of reserved 0 index\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","maxlen = 100\n","\n","X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n","X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n","\n","from numpy import array\n","from numpy import asarray\n","from numpy import zeros\n","\n","embeddings_dictionary = dict()\n","glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n","\n","for line in glove_file:\n","    records = line.split()\n","    word = records[0]\n","    vector_dimensions = asarray(records[1:], dtype='float32')\n","    embeddings_dictionary [word] = vector_dimensions\n","glove_file.close()\n","\n","\n","embedding_matrix = zeros((vocab_size, 100))\n","for word, index in tokenizer.word_index.items():\n","    embedding_vector = embeddings_dictionary.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[index] = embedding_vector\n","\n","### CNN\n","from keras.layers import Conv1D\n","model = Sequential()\n","\n","embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n","model.add(embedding_layer)\n","\n","model.add(Conv1D(128, 5, activation='relu'))\n","model.add(GlobalMaxPooling1D())\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n","\n","print(model.summary())\n","\n","\n","history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)\n","\n","score = model.evaluate(X_test, y_test, verbose=1)\n","\n","print(\"Test Score:\", score[0])\n","print(\"Test Accuracy:\", score[1])\n","\n","## predicted values\n","y_p = model.predict_classes(X_test)\n","y_pred = np.array(y_p).astype(int)\n","\n","## evaluation of CNN\n","\n","import numpy\n","import tensorflow as tf\n","tf.executing_eagerly()\n","\n","m = tf.keras.metrics.Accuracy() \n","_ = m.update_state(y_test, y_pred)\n","m.result().numpy()\n","\n","m = tf.keras.metrics.MeanAbsoluteError() \n","_ = m.update_state(y_test, y_pred) \n","m.result().numpy()\n","\n","m = tf.keras.metrics.Precision()\n","m.update_state(y_test, y_pred)\n","print('Precision: ', m.result().numpy())\n","\n","m = tf.keras.metrics.Recall()\n","m.update_state(y_test, y_pred)\n","print('Recall: ', m.result().numpy())\n","\n","m = tf.keras.metrics.RootMeanSquaredError()\n","m.update_state(y_test, y_pred)\n","print('RMSE: ', m.result().numpy())\n","\n","\n","### plot of accuracy and loss\n","\n","import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train','test'], loc = 'upper left')\n","plt.show()\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train','test'], loc = 'upper left')\n","plt.show()"],"execution_count":0,"outputs":[]}]}